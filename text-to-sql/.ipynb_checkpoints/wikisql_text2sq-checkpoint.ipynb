{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-02T06:10:48.583179Z",
     "iopub.status.busy": "2024-05-02T06:10:48.582752Z",
     "iopub.status.idle": "2024-05-02T06:10:48.638104Z",
     "shell.execute_reply": "2024-05-02T06:10:48.636945Z",
     "shell.execute_reply.started": "2024-05-02T06:10:48.583141Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20520\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T12:11:00.769741Z",
     "iopub.status.busy": "2023-03-17T12:11:00.769353Z",
     "iopub.status.idle": "2023-03-17T12:11:00.827471Z",
     "shell.execute_reply": "2023-03-17T12:11:00.826488Z",
     "shell.execute_reply.started": "2023-03-17T12:11:00.769703Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/wikisql/wikisql_schema_train.csv')\n",
    "df2 = df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T12:11:00.839598Z",
     "iopub.status.busy": "2023-03-17T12:11:00.838776Z",
     "iopub.status.idle": "2023-03-17T12:11:00.845808Z",
     "shell.execute_reply": "2023-03-17T12:11:00.844651Z",
     "shell.execute_reply.started": "2023-03-17T12:11:00.83956Z"
    }
   },
   "outputs": [],
   "source": [
    "questions = df2['question'].tolist()\n",
    "sql_queries = df2['sql'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the Name of the power station with a Capacity of 25 MW?',\n",
       " 'What was the corrected time of sail number aus70?',\n",
       " 'Which Nationality has a Player of keith bogans, and a Years in Orlando of 2006–2009?',\n",
       " 'What grade did jockey Robby Albarado get when racing with Ravens Pass?',\n",
       " 'In what place(s) did the player(s) with a total less than 282 finish?',\n",
       " 'What is the number of games for less than 2 seasons and more than 7 draws?',\n",
       " 'What is every 5-year peek with a when Anatoly Karpov, 2820 is 15-year peak?',\n",
       " 'What is the rating for the episode with the night rank of 11 and timeslot rank is larger than 4?',\n",
       " 'What was the percentage of total votes in 1997?',\n",
       " 'Which Away team has a Tie no of 4?',\n",
       " 'What is the earliest year Stuart Janney III was an owner?',\n",
       " 'What is GDP (PPP) Per Capita 2012 EU27 = 100, when GDP 2012 Millions Of Euro is 309,900?',\n",
       " 'What are the total lanes that have a rank larger than 22?',\n",
       " 'Which Melbourne had a gold coast and sydney which were yes, but an adelaide that was no?',\n",
       " 'Who is the builder with a works number of 2534?',\n",
       " 'If the Vinto Municipality is 18630, what is the Quillacollo Municipality?',\n",
       " 'What is the theme of the Year 2002 which was created by Artist Dan Fell?',\n",
       " 'Which Lead has Hans Frauenlob as a Third?',\n",
       " 'What is the System when the Licence is gpl and the Current Version is 1.72?',\n",
       " 'Who is the director of the original title perl oder pica?',\n",
       " 'What year did Culver leave?',\n",
       " 'Where is Dynamo-2 located?',\n",
       " 'How many 3 credits are there with 5 credits of 5?',\n",
       " 'what is the mascot when the county is 43 kosciusko?',\n",
       " 'What is the car make for Sterling Marlin?',\n",
       " \"If the Away team had a score of 14.14 (98), what's the name of the Away team?\",\n",
       " \"When was the date of appointment for St. Johnstone's manager? \",\n",
       " \"What is the Prince XML value for the engine that has a Gecko value of 'no' and webkit value of 'nightly build'?\",\n",
       " 'For which league is the open cup the quarter finals',\n",
       " 'Which release had 6 DVDs?',\n",
       " 'What is the lowest Game, when High Assists is \"Maurice Williams (8)\"?',\n",
       " 'What is the frequency of the station with a coverage of oaxaca guerrero puebla?',\n",
       " 'Name the production code for november 27, 1988',\n",
       " \"What was radio mexicana's website?\",\n",
       " 'What is the highest rank when Garry Kasparov, 2879 is the 1-year peak?',\n",
       " 'Who had fa cup goals of 0, league cup goals less than 2, and total goals of 2?',\n",
       " 'During which years was the model with the Engine code of m54b25 manufactured?',\n",
       " 'Nationality of england, and a Lost larger than 39, and a Win % of 28.7, and a Drawn smaller than 37 had what sum of matches?',\n",
       " 'What is the barrel length for a cold model le6921sp?',\n",
       " 'What date has a Game site of bye?',\n",
       " 'Which Opponent has a Record of 65-95?',\n",
       " 'What is the ERP W for K236AM?',\n",
       " 'Name the least age 30-39 where age 20-29 is 593',\n",
       " 'What is the tyre of real racing with leon team member koudai tsukakoshi?',\n",
       " 'What is week 3 when week 6 is 26.05?',\n",
       " 'What is the position of the player from the college of North Carolina with an overall less than 100?',\n",
       " 'what was the largest attendance at kardinia park?',\n",
       " \"What aired at 9:30 when Don't Forget the Lyrics aired at 8:00?\",\n",
       " 'Who wrote the episode \"victor/victorious\"?',\n",
       " 'Which operating system has a storage (flash) of 128MB?',\n",
       " 'Can you tell me the Game that has the Opponent of miami heat?',\n",
       " 'Who was the top picki n the draft?',\n",
       " 'Name the date when result is l 13–10 ot',\n",
       " 'What was the home team that had a score of 6.20 (56)',\n",
       " 'What episode number in the series is \"dance to the music\"?',\n",
       " 'Which year has an Engine(s) of yamaha v8?',\n",
       " 'Name the score for howard (8) high rebounds',\n",
       " 'When 1522 is the tonnes of co2 saved what is the year?',\n",
       " 'What is the status when the rank is 2?',\n",
       " 'Which City has 600kw 500kw ERP ?',\n",
       " 'What is the average Wins, when F/Laps is greater than 1, and when Points is 80?',\n",
       " 'Tell me the 2008 of 2001 olympic games',\n",
       " 'Who won the race on August 15?',\n",
       " 'What was the surface where the opponent was Nathalie Dechy Meilen Tu?',\n",
       " 'what is the total number of\\xa0player\\xa0where\\xa0years for rockets\\xa0is 2004-06',\n",
       " 'what is the title of the episode with the production code of ad1a22?',\n",
       " 'What are the lowest conceded with 1 draw, and a score larger than 14?',\n",
       " 'Which band plays Self Versus Self - Immersion?',\n",
       " 'What was the title of the episode directed by John T. Kretchmer? ',\n",
       " 'What was the original title of the Hindi film?',\n",
       " 'What venue featured a home score of 8.9 (57)?',\n",
       " 'Name the gene name for methylobacterium nodulans',\n",
       " 'What is the location/attendance with a 26-11 record?',\n",
       " 'Name the high points for april 8',\n",
       " 'What is the lowest Score, when Place is \"1\"?',\n",
       " 'What is the Website of Head Coach Yuriy Korotkevich?',\n",
       " 'Name the total number when date is 30 may 2010',\n",
       " 'How many assists did Steve Walker have?',\n",
       " 'What is the school of the player who went to the college of michigan and originally comes from Wheaton, Illinois?',\n",
       " 'What is the rank of the 150.163 qual?',\n",
       " 'What was the time for the match with away team Shatin?',\n",
       " 'Who is the candidate wehre district is louisiana 1?',\n",
       " 'What is the largest crowd at Lake Oval?',\n",
       " 'What is the total reg gp of Ilya Krikunov, who has a round of 7 and a pick number larger than 223?',\n",
       " 'What was the score on January 14 when the Chicago Black Hawks were home against the New York Rangers?',\n",
       " 'Which country has a reaction time of under 0.242 seconds and over 1041 points?',\n",
       " 'What was the successor for vacant alabama 3rd?',\n",
       " 'What is the name of the home team that played away team Footscray?',\n",
       " 'Tell me the result for 2010 fifa world cup qualification',\n",
       " 'What is Score, when Attendance is 2,444?',\n",
       " 'What was the margin of victory when the winning score was –14 (70-68-67=205)?',\n",
       " 'What was the highest amount of episodes for the season with 5.74 million viewers?',\n",
       " 'What is the other name for martonoš?',\n",
       " 'Which of the countries showed a score of 71-72=143?',\n",
       " 'What date final has 1989 as the year?',\n",
       " 'Which round had a winning driver of Uwe Alzen, at the Sepang International circuit?',\n",
       " 'How many  year locations are there for the womens doubles in jing junhong li jiawei?',\n",
       " 'Which Player has a Hc Cska Moscow (Russia)?',\n",
       " 'What was the emission rating in Mid-Atlantic South for the vehicle that was rated 300 g/mi (186 g/km) in the Midwest?',\n",
       " 'What Republican District had Incumbent First Elected in 2000 then Re-elected?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SELECT Name FROM table WHERE Capacity (MW) = 25',\n",
       " 'SELECT Corrected Time d:hh:mm:ss FROM table WHERE Sail Number = AUS70',\n",
       " 'SELECT Nationality FROM table WHERE Player = keith bogans AND Years in Orlando = 2006–2009',\n",
       " 'SELECT Grade FROM table WHERE Jockey = robby albarado AND Runner up/Winner = ravens pass',\n",
       " 'SELECT Finish FROM table WHERE Total < 282',\n",
       " 'SELECT SUM total games FROM table WHERE number of seasons < 2 AND Draw > 7',\n",
       " 'SELECT 5-year peak FROM table WHERE 15-year peak = Anatoly Karpov, 2820',\n",
       " 'SELECT AVG Rating FROM table WHERE Night Rank = 11 AND Timeslot Rank > 4',\n",
       " 'SELECT % of total vote FROM table WHERE Year = 1997',\n",
       " 'SELECT Away team FROM table WHERE Tie no = 4',\n",
       " 'SELECT MIN Year FROM table WHERE Owner = stuart janney iii',\n",
       " 'SELECT GDP (PPP) per capita 2012 EU27 = 100 FROM table WHERE GDP 2012 millions of euro = 309,900',\n",
       " 'SELECT SUM Lane FROM table WHERE Rank > 22',\n",
       " 'SELECT Melbourne FROM table WHERE Gold Coast = yes AND Adelaide = no AND Sydney = yes',\n",
       " 'SELECT Builder FROM table WHERE Works number = 2534',\n",
       " 'SELECT MAX Quillacollo Municipality FROM table WHERE Vinto Municipality = 18630',\n",
       " 'SELECT Theme FROM table WHERE Year = 2002 AND Artist = dan fell',\n",
       " 'SELECT Lead FROM table WHERE Third = hans frauenlob',\n",
       " 'SELECT System FROM table WHERE License = gpl AND Current version = 1.72',\n",
       " 'SELECT Director FROM table WHERE Original title = Perl oder Pica',\n",
       " 'SELECT SUM Year left FROM table WHERE Location = culver',\n",
       " 'SELECT Location FROM table WHERE Team = dynamo-2',\n",
       " 'SELECT COUNT 3 credits FROM table WHERE 5 credits = 5',\n",
       " 'SELECT Mascot FROM table WHERE County = 43 kosciusko',\n",
       " 'SELECT Car Make FROM table WHERE Driver = Sterling Marlin',\n",
       " 'SELECT Away team FROM table WHERE Away team score = 14.14 (98)',\n",
       " 'SELECT Date of appointment FROM table WHERE Team = St. Johnstone',\n",
       " 'SELECT Prince XML FROM table WHERE Gecko = no AND WebKit = nightly build',\n",
       " 'SELECT League FROM table WHERE Open Cup = Quarter Finals',\n",
       " 'SELECT Release FROM table WHERE # of discs = 6',\n",
       " 'SELECT MIN Game FROM table WHERE High assists = maurice williams (8)',\n",
       " 'SELECT Frequency FROM table WHERE Coverage = oaxaca guerrero puebla',\n",
       " 'SELECT Production code FROM table WHERE Original air date = November 27, 1988',\n",
       " 'SELECT Website FROM table WHERE Brand = radio mexicana',\n",
       " 'SELECT MAX Rank FROM table WHERE 1-year peak = Garry Kasparov, 2879',\n",
       " 'SELECT Name FROM table WHERE FA Cup Goals = 0 AND League Cup Goals < 2 AND Total Goals = 2',\n",
       " 'SELECT Years FROM table WHERE Engine code = m54b25',\n",
       " 'SELECT SUM Matches FROM table WHERE Nationality = england AND Lost > 39 AND Win % = 28.7 AND Drawn < 37',\n",
       " 'SELECT Barrel length FROM table WHERE Colt model no. = LE6921SP',\n",
       " 'SELECT Date FROM table WHERE Game site = bye',\n",
       " 'SELECT Opponent FROM table WHERE Record = 65-95',\n",
       " 'SELECT ERP W FROM table WHERE Call sign = k236am',\n",
       " 'SELECT MIN Age 30-39 FROM table WHERE Age 20-29 = 593',\n",
       " 'SELECT Tyre FROM table WHERE Team = real racing with leon AND Drivers = koudai tsukakoshi',\n",
       " 'SELECT Week 3 FROM table WHERE Week 6 = 26.05',\n",
       " 'SELECT Position FROM table WHERE Overall < 100 AND College = north carolina',\n",
       " 'SELECT MAX Crowd FROM table WHERE Venue = kardinia park',\n",
       " \"SELECT 9:30 FROM table WHERE 8:00 = don't forget the lyrics\",\n",
       " 'SELECT Written by FROM table WHERE Title = \"Victor/Victorious\"',\n",
       " 'SELECT Operating system version FROM table WHERE Storage ( flash ) = 128mb',\n",
       " 'SELECT Game FROM table WHERE Opponent = miami heat',\n",
       " 'SELECT MIN Choice FROM table',\n",
       " 'SELECT Date FROM table WHERE Result = L 13–10 OT',\n",
       " 'SELECT Home team FROM table WHERE Home team score = 6.20 (56)',\n",
       " 'SELECT MIN No. in series FROM table WHERE Title = \"Dance to the Music\"',\n",
       " 'SELECT Year FROM table WHERE Engine(s) = yamaha v8',\n",
       " 'SELECT Score FROM table WHERE High rebounds = howard (8)',\n",
       " 'SELECT Year FROM table WHERE Tonnes of CO2 Saved = 1522',\n",
       " 'SELECT Status FROM table WHERE Rank = 2',\n",
       " 'SELECT City FROM table WHERE ERP (Analog/ Digital) = 600kw 500kw',\n",
       " 'SELECT AVG Wins FROM table WHERE F/Laps > 1 AND Points = 80',\n",
       " 'SELECT 2008 FROM table WHERE 2011 = olympic games',\n",
       " 'SELECT Race Winner FROM table WHERE Date = August 15',\n",
       " 'SELECT Surface FROM table WHERE Opponent in the final = nathalie dechy meilen tu',\n",
       " 'SELECT COUNT Player FROM table WHERE Years for Rockets = 2004-06',\n",
       " 'SELECT Title FROM table WHERE Production code = ad1a22',\n",
       " 'SELECT MIN Conceded FROM table WHERE Draws = 1 AND Scored > 14',\n",
       " 'SELECT Band FROM table WHERE Album or Song = self versus self - immersion',\n",
       " 'SELECT Title FROM table WHERE Directed by = John T. Kretchmer',\n",
       " 'SELECT Original title FROM table WHERE Language = hindi',\n",
       " 'SELECT Venue FROM table WHERE Home team score = 8.9 (57)',\n",
       " 'SELECT Gene Name FROM table WHERE Genus/Species = Methylobacterium nodulans',\n",
       " 'SELECT Location Attendance FROM table WHERE Record = 26-11',\n",
       " 'SELECT High points FROM table WHERE Date = April 8',\n",
       " 'SELECT MIN Score FROM table WHERE Place = 1',\n",
       " 'SELECT Website FROM table WHERE Head Coach = yuriy korotkevich',\n",
       " 'SELECT COUNT No. FROM table WHERE Date = 30 May 2010',\n",
       " 'SELECT Assists FROM table WHERE Player = steve walker',\n",
       " 'SELECT School FROM table WHERE College = michigan AND Hometown = wheaton, illinois',\n",
       " 'SELECT Rank FROM table WHERE Qual = 150.163',\n",
       " 'SELECT Time FROM table WHERE Away team = shatin',\n",
       " 'SELECT Candidates FROM table WHERE District = Louisiana 1',\n",
       " 'SELECT MAX Crowd FROM table WHERE Venue = lake oval',\n",
       " 'SELECT COUNT Reg GP FROM table WHERE Rd # = 7 AND Player = ilya krikunov AND Pick # > 223',\n",
       " 'SELECT Score FROM table WHERE Home = chicago black hawks AND Visitor = new york rangers AND Date = january 14',\n",
       " 'SELECT Country FROM table WHERE React < 0.242 AND Points > 1041',\n",
       " 'SELECT Successor FROM table WHERE Vacator = Vacant AND District = Alabama 3rd',\n",
       " 'SELECT Home team FROM table WHERE Away team = footscray',\n",
       " 'SELECT Result FROM table WHERE Competition = 2010 fifa world cup qualification',\n",
       " 'SELECT Score FROM table WHERE Attendance = 2,444',\n",
       " 'SELECT Margin of victory FROM table WHERE Winning score = –14 (70-68-67=205)',\n",
       " 'SELECT MAX Episodes FROM table WHERE Viewers (in millions) = 5.74',\n",
       " 'SELECT Cyrillic Name Other Names FROM table WHERE Settlement = Martonoš',\n",
       " 'SELECT Country FROM table WHERE Score = 71-72=143',\n",
       " 'SELECT Date Final FROM table WHERE Year = 1989',\n",
       " 'SELECT Round FROM table WHERE Winning Driver = uwe alzen AND Circuit = sepang international circuit',\n",
       " 'SELECT COUNT Year Location FROM table WHERE Womens Doubles = Jing Junhong Li Jiawei',\n",
       " 'SELECT Player FROM table WHERE College/Junior/Club Team (League) = hc cska moscow (russia)',\n",
       " 'SELECT Mid-Atlantic South (Washington, D.C.) FROM table WHERE Midwest (Des Moines) = 300 g/mi (186 g/km)',\n",
       " 'SELECT District FROM table WHERE Party = republican AND Results = re-elected AND First elected = 2000']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T12:11:00.848753Z",
     "iopub.status.busy": "2023-03-17T12:11:00.847818Z",
     "iopub.status.idle": "2023-03-17T12:11:01.051063Z",
     "shell.execute_reply": "2023-03-17T12:11:01.050017Z",
     "shell.execute_reply.started": "2023-03-17T12:11:00.84871Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "tokenized_inputs = tokenizer.batch_encode_plus(questions, padding=True, truncation=True, return_tensors='pt')\n",
    "tokenized_outputs = tokenizer.batch_encode_plus(sql_queries, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T12:11:01.052997Z",
     "iopub.status.busy": "2023-03-17T12:11:01.052633Z",
     "iopub.status.idle": "2023-03-17T12:11:01.06133Z",
     "shell.execute_reply": "2023-03-17T12:11:01.059121Z",
     "shell.execute_reply.started": "2023-03-17T12:11:01.052962Z"
    }
   },
   "outputs": [],
   "source": [
    "class SQLOnlineDataset(Dataset):\n",
    "    def __init__(self, tokenized_inputs, tokenized_outputs):\n",
    "        self.input_ids = tokenized_inputs['input_ids']\n",
    "        self.attention_mask = tokenized_inputs['attention_mask']\n",
    "        self.labels = tokenized_outputs['input_ids']\n",
    "        self.decoder_attention_mask = tokenized_outputs['attention_mask']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_mask[idx],\n",
    "            'labels': self.labels[idx],\n",
    "            'decoder_attention_mask': self.decoder_attention_mask[idx]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T12:11:01.063752Z",
     "iopub.status.busy": "2023-03-17T12:11:01.063316Z",
     "iopub.status.idle": "2023-03-17T12:11:01.073628Z",
     "shell.execute_reply": "2023-03-17T12:11:01.072255Z",
     "shell.execute_reply.started": "2023-03-17T12:11:01.063705Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = SQLOnlineDataset(tokenized_inputs, tokenized_outputs)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T12:11:01.075875Z",
     "iopub.status.busy": "2023-03-17T12:11:01.075279Z",
     "iopub.status.idle": "2023-03-17T12:11:05.398877Z",
     "shell.execute_reply": "2023-03-17T12:11:05.397718Z",
     "shell.execute_reply.started": "2023-03-17T12:11:01.075837Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T12:11:05.403589Z",
     "iopub.status.busy": "2023-03-17T12:11:05.402622Z",
     "iopub.status.idle": "2023-03-17T12:11:05.415607Z",
     "shell.execute_reply": "2023-03-17T12:11:05.414364Z",
     "shell.execute_reply.started": "2023-03-17T12:11:05.40355Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T12:11:05.419144Z",
     "iopub.status.busy": "2023-03-17T12:11:05.418666Z",
     "iopub.status.idle": "2023-03-17T12:11:49.105181Z",
     "shell.execute_reply": "2023-03-17T12:11:49.103928Z",
     "shell.execute_reply.started": "2023-03-17T12:11:05.419103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.234610676765442\n",
      "Epoch: 2, Loss: 0.9591853618621826\n",
      "Epoch: 3, Loss: 0.935570478439331\n",
      "Epoch: 4, Loss: 0.5132601857185364\n",
      "Epoch: 5, Loss: 0.8935773372650146\n",
      "Epoch: 6, Loss: 0.4368203580379486\n",
      "Epoch: 7, Loss: 0.4976617097854614\n",
      "Epoch: 8, Loss: 0.3810380697250366\n",
      "Epoch: 9, Loss: 0.45266959071159363\n",
      "Epoch: 10, Loss: 0.5406204462051392\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        decoder_attention_mask = batch['decoder_attention_mask'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T12:11:49.107406Z",
     "iopub.status.busy": "2023-03-17T12:11:49.106732Z",
     "iopub.status.idle": "2023-03-17T12:11:51.070819Z",
     "shell.execute_reply": "2023-03-17T12:11:51.069294Z",
     "shell.execute_reply.started": "2023-03-17T12:11:49.107366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model/sql_t5_tokenizer\\\\tokenizer_config.json',\n",
       " 'model/sql_t5_tokenizer\\\\special_tokens_map.json',\n",
       " 'model/sql_t5_tokenizer\\\\spiece.model',\n",
       " 'model/sql_t5_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('model/wikisql_t5_model')\n",
    "tokenizer.save_pretrained('model/sql_t5_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T12:11:51.082745Z",
     "iopub.status.busy": "2023-03-17T12:11:51.079866Z",
     "iopub.status.idle": "2023-03-17T12:12:00.217498Z",
     "shell.execute_reply": "2023-03-17T12:12:00.20826Z",
     "shell.execute_reply.started": "2023-03-17T12:11:51.08268Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model/wikisql_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T12:12:00.227167Z",
     "iopub.status.busy": "2023-03-17T12:12:00.225103Z",
     "iopub.status.idle": "2023-03-17T12:12:04.664068Z",
     "shell.execute_reply": "2023-03-17T12:12:04.662894Z",
     "shell.execute_reply.started": "2023-03-17T12:12:00.227119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "model.load_state_dict(torch.load('model/wikisql_model.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T12:12:04.666628Z",
     "iopub.status.busy": "2023-03-17T12:12:04.665759Z",
     "iopub.status.idle": "2023-03-17T12:12:04.845268Z",
     "shell.execute_reply": "2023-03-17T12:12:04.84426Z",
     "shell.execute_reply.started": "2023-03-17T12:12:04.666587Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T12:14:50.527997Z",
     "iopub.status.busy": "2023-03-17T12:14:50.526954Z",
     "iopub.status.idle": "2023-03-17T12:14:53.493809Z",
     "shell.execute_reply": "2023-03-17T12:14:53.492646Z",
     "shell.execute_reply.started": "2023-03-17T12:14:50.527929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many heads of the departments are older than 56 ?\n",
      "Generated SQL query: How many heads of departments are older than 56?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_question = \"How many heads of the departments are older than 56 ?\"\n",
    "input_ids = tokenizer.encode(new_question, return_tensors='pt')\n",
    "outputs = model.generate(input_ids=input_ids, max_length=100, num_beams=5, early_stopping=True)\n",
    "sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Question: {new_question}\")\n",
    "print(f\"Generated SQL query: {sql_query}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  571,   186,  7701,    13,     8, 10521,    33,  2749,   145, 11526,\n",
       "             3,    58,     1]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1456187,
     "sourceId": 2409983,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30407,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
