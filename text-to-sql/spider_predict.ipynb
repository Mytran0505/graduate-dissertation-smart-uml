{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20520\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\20520\\AppData\\Local\\Temp\\ipykernel_18940\\787579030.py:12: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  exact_match_metric = load_metric(\"exact_match\")\n",
      "C:\\Users\\20520\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for exact_match contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/exact_match/exact_match.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")\n",
    "from datasets import load_metric\n",
    "exact_match_metric = load_metric(\"exact_match\")\n",
    "lb = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load l·∫°i m√¥ h√¨nh v√† tokenizer ƒë·ªÉ ki·ªÉm tra\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "model.load_state_dict(torch.load('model/spider/spider_model.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Validation text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sentences = 100\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/spider/spider_schema_validation.csv\", nrows = total_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate SQL query\n",
    "def generate_sql_query(question):\n",
    "    input_ids = tokenizer.encode(question, return_tensors='pt')\n",
    "    outputs = model.generate(input_ids=input_ids, max_length=100, num_beams=5, early_stopping=True)\n",
    "    sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return sql_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SQL queries for each question in the CSV\n",
    "df['sql_query'] = df['question'].apply(generate_sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL queries saved to data/spider/spider_tex2sql_predict.csv\n"
     ]
    }
   ],
   "source": [
    "output_df = df[['question','sql','sql_query']]\n",
    "# Save the results to a new CSV file\n",
    "output_file = \"data/spider/spider_tex2sql_predict.csv\"\n",
    "output_df.to_csv(output_file, index=False)\n",
    "print(f\"Generated SQL queries saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get sql and sql predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sql(sql_query):\n",
    "    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng d∆∞ th·ª´a\n",
    "    sql_query = re.sub(r'\\s+', ' ', sql_query)\n",
    "\n",
    "    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng tr∆∞·ªõc d·∫•u ph·∫©y\n",
    "    sql_query = re.sub(r'\\s*,', ',', sql_query)\n",
    "\n",
    "    # ƒê·ªïi d·∫•u c√°ch tr∆∞·ªõc v√† sau c√°c to√°n t·ª≠ so s√°nh\n",
    "    sql_query = re.sub(r'(\\S)([><=]+)(\\S)', r'\\1 \\2 \\3', sql_query)\n",
    "\n",
    "    # Chu·∫©n h√≥a c√°c t·ª´ kh√≥a SQL\n",
    "    sql_keywords = ['SELECT', 'FROM', 'WHERE', 'AND', 'OR', 'NOT', 'ORDER BY', 'GROUP BY', 'HAVING', 'LIMIT']\n",
    "    for keyword in sql_keywords:\n",
    "        sql_query = re.sub(r'\\b' + keyword.lower() + r'\\b', keyword, sql_query, flags=re.IGNORECASE)\n",
    "\n",
    "    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng ·ªü ƒë·∫ßu v√† cu·ªëi c√¢u SQL\n",
    "    sql_query = sql_query.strip()\n",
    "\n",
    "    # Th√™m d·∫•u c√°ch sau d·∫•u ph·∫©y n·∫øu sau d·∫•u ph·∫©y kh√¥ng c√≥ kho·∫£ng tr·∫Øng\n",
    "    sql_query = re.sub(r',(?!\\s)', ', ', sql_query)\n",
    "\n",
    "    return sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"sql\"].apply(preprocess_sql)\n",
    "predictions = df['sql_query'].apply(preprocess_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric: rocauc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "S·ªë li·ªáu n√†y t√≠nh to√°n di·ªán t√≠ch d∆∞·ªõi ƒë∆∞·ªùng cong (AUC) cho ƒê∆∞·ªùng cong ƒë·∫∑c t√≠nh ho·∫°t ƒë·ªông c·ªßa m√°y thu (ROC). C√°c gi√° tr·ªã tr·∫£ v·ªÅ th·ªÉ hi·ªán m·ª©c ƒë·ªô d·ª± ƒëo√°n ch√≠nh x√°c c·ªßa m√¥ h√¨nh ƒë∆∞·ª£c s·ª≠ d·ª•ng d·ª±a tr√™n d·ªØ li·ªáu ƒë·∫ßu v√†o. ƒêi·ªÉm 0,5 c√≥ nghƒ©a l√† m√¥ h√¨nh ƒëang d·ª± ƒëo√°n ch√≠nh x√°c m·ªôt c√°ch ng·∫´u nhi√™n, t·ª©c l√† c√°c d·ª± ƒëo√°n c·ªßa m√¥ h√¨nh ƒë√∫ng v·ªõi t·ª∑ l·ªá t∆∞∆°ng t·ª± nh∆∞ khi c√°c d·ª± ƒëo√°n ƒë∆∞·ª£c quy·∫øt ƒë·ªãnh b·∫±ng c√°ch tung ƒë·ªìng xu c√¥ng b·∫±ng ho·∫∑c tung x√∫c x·∫Øc c√¥ng b·∫±ng. \n",
    "\n",
    "ƒêi·ªÉm tr√™n 0,5 cho th·∫•y m√¥ h√¨nh ƒëang ho·∫°t ƒë·ªông t·ªët h∆°n c∆° h·ªôi, trong khi ƒëi·ªÉm d∆∞·ªõi 0,5 cho th·∫•y m√¥ h√¨nh ƒëang ho·∫°t ƒë·ªông k√©m h∆°n c∆° h·ªôi.\n",
    "\n",
    "C√≥ ba tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng ri√™ng bi·ªát:\n",
    "\n",
    "binary: Tr∆∞·ªùng h·ª£p ch·ªâ c√≥ hai l·ªõp nh√£n kh√°c nhau v√† m·ªói m·∫´u ch·ªâ c√≥ m·ªôt nh√£n. ƒê√¢y l√† c√°ch th·ª±c hi·ªán m·∫∑c ƒë·ªãnh.\n",
    "multiclass: Tr∆∞·ªùng h·ª£p c√≥ th·ªÉ c√≥ nhi·ªÅu h∆°n hai l·ªõp nh√£n kh√°c nhau, nh∆∞ng m·ªói m·∫´u v·∫´n ch·ªâ c√≥ m·ªôt nh√£n.\n",
    "multilabel: Tr∆∞·ªùng h·ª£p c√≥ th·ªÉ c√≥ nhi·ªÅu h∆°n hai l·ªõp nh√£n kh√°c nhau v√† m·ªói v√≠ d·ª• c√≥ th·ªÉ c√≥ nhi·ªÅu h∆°n m·ªôt nh√£n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate ROC AUC for multiclass\n",
    "def calculate_multiclass_roc_auc(target, predictions):\n",
    "    '''\n",
    "    This method returns the AUC Score for multiclass classification\n",
    "    '''\n",
    "    # Check if the predictions are probabilities or labels\n",
    "    if len(predictions.shape) == 1 or predictions.shape[1] == 1:\n",
    "        predictions_binarized = lb.transform(predictions)\n",
    "    else:\n",
    "        predictions_binarized = predictions\n",
    "    \n",
    "    return metrics.roc_auc_score(target, predictions_binarized, multi_class='ovr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_binarized = lb.fit_transform(target)\n",
    "predictions_binarized = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.8642338291248703\n"
     ]
    }
   ],
   "source": [
    "# Calculate the ROC AUC score for multiclass\n",
    "roc_auc_score = calculate_multiclass_roc_auc(target_binarized, predictions_binarized)\n",
    "\n",
    "print(f\"ROC AUC Score: {roc_auc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric: exact_match"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Exact Match Accuracy: ƒê√¢y l√† ƒë·ªô ƒëo ƒë∆°n gi·∫£n v√† tr·ª±c quan nh·∫•t. N√≥ ki·ªÉm tra xem c√¢u SQL d·ª± ƒëo√°n c√≥ kh·ªõp ho√†n to√†n v·ªõi c√¢u SQL g·ªëc hay kh√¥ng. ƒê·ªô ch√≠nh x√°c n√†y ch·ªâ cao khi to√†n b·ªô c√¢u SQL d·ª± ƒëo√°n ho√†n to√†n kh·ªõp v·ªõi c√¢u SQL g·ªëc, bao g·ªìm c·∫£ t·ª´ kh√≥a, t√™n b·∫£ng, t√™n c·ªôt, v√† gi√° tr·ªã.\n",
    "\n",
    "∆Øu ƒëi·ªÉm: R·∫•t tr·ª±c quan v√† d·ªÖ hi·ªÉu.\n",
    "Nh∆∞·ª£c ƒëi·ªÉm: Kh√° nghi√™m ng·∫∑t v√† c√≥ th·ªÉ kh√¥ng c√¥ng b·∫±ng trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p, nh∆∞ khi ch·ªâ c√≥ sai s√≥t nh·ªè nh∆∞ng kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn √Ω nghƒ©a c·ªßa c√¢u SQL."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Regex_to_ignore (danh s√°ch str): Bi·ªÉu th·ª©c Regex c·ªßa c√°c k√Ω t·ª± c·∫ßn b·ªè qua khi t√≠nh to√°n k·∫øt qu·∫£ kh·ªõp ch√≠nh x√°c. M·∫∑c ƒë·ªãnh l√† Kh√¥ng. L∆∞u √Ω: c√°c thay ƒë·ªïi bi·ªÉu th·ª©c ch√≠nh quy ƒë∆∞·ª£c √°p d·ª•ng tr∆∞·ªõc khi vi·∫øt hoa ƒë∆∞·ª£c chu·∫©n h√≥a.\n",
    "\n",
    "ign_case (bool): N·∫øu ƒê√∫ng, chuy·ªÉn m·ªçi th·ª© th√†nh ch·ªØ th∆∞·ªùng ƒë·ªÉ b·ªè qua s·ª± kh√°c bi·ªát v·ªÅ c√°ch vi·∫øt hoa. M·∫∑c ƒë·ªãnh l√† Sai.\n",
    "\n",
    "ign_punctuation (bool): N·∫øu ƒê√∫ng, x√≥a d·∫•u c√¢u tr∆∞·ªõc khi so s√°nh c√°c chu·ªói. M·∫∑c ƒë·ªãnh l√† Sai.\n",
    "\n",
    "ign_numbers (bool): N·∫øu ƒê√∫ng, x√≥a t·∫•t c·∫£ c√°c ch·ªØ s·ªë tr∆∞·ªõc khi so s√°nh chu·ªói. M·∫∑c ƒë·ªãnh l√† Sai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match': 75.0}\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 3:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT creation, name, budget_in_year FROM department\n",
      "C√¢u tham chi·∫øu: SELECT creation, name, budget_in_billions FROM department\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 4:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT max(budget_in_billion), min(budget_in_billion) FROM department\n",
      "C√¢u tham chi·∫øu: SELECT max(budget_in_billions), min(budget_in_billions) FROM department\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 5:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT avg(num_employees) FROM department WHERE rank BETWEEN 10 AND 15\n",
      "C√¢u tham chi·∫øu: SELECT avg(num_employees) FROM department WHERE ranking BETWEEN 10 AND 15\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 6:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT name FROM head WHERE born_state!= 'California'\n",
      "C√¢u tham chi·∫øu: SELECT name FROM head WHERE born_state != 'California'\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 13:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT DISTINCT T1.age FROM management AS T1 JOIN head AS T2 ON T1.head_id = T2.head_id WHERE T2.temporary_acting = 'Yes'\n",
      "C√¢u tham chi·∫øu: SELECT DISTINCT T1.age FROM management AS T2 JOIN head AS T1 ON T1.head_id = T2.head_id WHERE T2.temporary_acting = 'Yes'\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 14:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT T3.born_state FROM department AS T1 JOIN management AS T2 ON T1.department_id = T2.department_id JOIN head AS T3 ON T2.head_id = T3.head_id WHERE T1.name = 'Treasury' INTERSECT SELECT T3.born_state FROM department AS T1 JOIN management AS T2 ON T\n",
      "C√¢u tham chi·∫øu: SELECT T3.born_state FROM department AS T1 JOIN management AS T2 ON T1.department_id = T2.department_id JOIN head AS T3 ON T2.head_id = T3.head_id WHERE T1.name = 'Treasury' INTERSECT SELECT T3.born_state FROM department AS T1 JOIN management AS T2 ON T1.department_id = T2.department_id JOIN head AS T3 ON T2.head_id = T3.head_id WHERE T1.name = 'Homeland Security'\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 15:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT T1.department_id, T1.name, count(*) FROM management AS T1 JOIN department AS T2 ON T1.department_id = T2.department_id GROUP BY T1.department_id HAVING count(*) > 1\n",
      "C√¢u tham chi·∫øu: SELECT T1.department_id, T1.name, count(*) FROM management AS T2 JOIN department AS T1 ON T1.department_id = T2.department_id GROUP BY T1.department_id HAVING count(*) > 1\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 21:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT Hosts FROM farm_competition WHERE Theme!= 'Aliens'\n",
      "C√¢u tham chi·∫øu: SELECT Hosts FROM farm_competition WHERE Theme != 'Aliens'\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 22:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT Hosts FROM farm_competition WHERE Theme!= 'Aliens'\n",
      "C√¢u tham chi·∫øu: SELECT Hosts FROM farm_competition WHERE Theme != 'Aliens'\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 45:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT Status FROM city GROUP BY Status ORDER BY COUNT(*)\n",
      "C√¢u tham chi·∫øu: SELECT Status FROM city GROUP BY Status ORDER BY COUNT(*) ASC\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 49:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT Official_Name FROM city WHERE City_ID NOT IN (SELECT Host_city_ID FROM competition)\n",
      "C√¢u tham chi·∫øu: SELECT Official_Name FROM city WHERE City_ID NOT IN (SELECT Host_city_ID FROM farm_competition)\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 51:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT Status FROM city WHERE Population > 1500 INTERSECT SELECT Status FROM city WHERE Population 500\n",
      "C√¢u tham chi·∫øu: SELECT Status FROM city WHERE Population > 1500 INTERSECT SELECT Status FROM city WHERE Population < 500\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 52:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT Status FROM city WHERE Population > 1500 INTERSECT SELECT Status FROM city WHERE Population 500\n",
      "C√¢u tham chi·∫øu: SELECT Status FROM city WHERE Population > 1500 INTERSECT SELECT Status FROM city WHERE Population < 500\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 53:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT Official_Name FROM city WHERE Population > 1500 OR Population 500\n",
      "C√¢u tham chi·∫øu: SELECT Official_Name FROM city WHERE Population > 1500 OR Population < 500\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 54:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT Official_Name FROM city WHERE Population > 1500 OR Population 500\n",
      "C√¢u tham chi·∫øu: SELECT Official_Name FROM city WHERE Population > 1500 OR Population < 500\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 55:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT Census_Ranking FROM city WHERE Status!= \"Village\"\n",
      "C√¢u tham chi·∫øu: SELECT Census_Ranking FROM city WHERE Status != \"Village\"\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 56:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT Census_Ranking FROM city WHERE Status!= \"Village\"\n",
      "C√¢u tham chi·∫øu: SELECT Census_Ranking FROM city WHERE Status != \"Village\"\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 57:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT T1.course_name FROM courses AS T1 JOIN student_course_registrations AS T2 ON T1.course_id = T2.course_id GROUP BY T1.course_id ORDER BY count(*) DESC LIMIT 1\n",
      "C√¢u tham chi·∫øu: SELECT T1.course_name FROM courses AS T1 JOIN student_course_registrations AS T2 ON T1.course_id = T2.course_Id GROUP BY T1.course_id ORDER BY count(*) DESC LIMIT 1\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 58:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT T1.course_name FROM courses AS T1 JOIN student_course_registrations AS T2 ON T1.course_id = T2.course_id GROUP BY T1.course_id ORDER BY count(*) DESC LIMIT 1\n",
      "C√¢u tham chi·∫øu: SELECT T1.course_name FROM courses AS T1 JOIN student_course_registrations AS T2 ON T1.course_id = T2.course_Id GROUP BY T1.course_id ORDER BY count(*) DESC LIMIT 1\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 63:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT student_id FROM student_course_attendance\n",
      "C√¢u tham chi·∫øu: SELECT student_id FROM students WHERE student_id NOT IN (SELECT student_id FROM student_course_attendance)\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 64:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT student_id FROM student_course_attendance\n",
      "C√¢u tham chi·∫øu: SELECT student_id FROM students WHERE student_id NOT IN (SELECT student_id FROM student_course_attendance)\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 72:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT count(*) FROM Courses AS T1 JOIN Student AS T2 ON T1.student_id = T2.student_id WHERE T2.student_id = 171\n",
      "C√¢u tham chi·∫øu: SELECT count(*) FROM courses AS T1 JOIN student_course_attendance AS T2 ON T1.course_id = T2.course_id WHERE T2.student_id = 171\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 87:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT T3.cell_mobile_number FROM candidates AS T1 JOIN candidate_assessments AS T2 ON T1.candidate_id = T2.candidate_id JOIN people AS T3 ON T1.candidate_id = T3.person_id WHERE T1.asessment_outcome_code = \"Fail\"\n",
      "C√¢u tham chi·∫øu: SELECT T3.cell_mobile_number FROM candidates AS T1 JOIN candidate_assessments AS T2 ON T1.candidate_id = T2.candidate_id JOIN people AS T3 ON T1.candidate_id = T3.person_id WHERE T2.asessment_outcome_code = \"Fail\"\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 92:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT DISTINCT T1.city FROM addresses AS T1 JOIN people AS T2 ON T1.address_id = T2.address_id\n",
      "C√¢u tham chi·∫øu: SELECT DISTINCT T1.city FROM addresses AS T1 JOIN people_addresses AS T2 ON T1.address_id = T2.address_id\n",
      "\n",
      "C·∫∑p kh√¥ng kh·ªõp th·ª© 95:\n",
      "C√¢u d·ª± ƒëo√°n: SELECT DISTINCT T1.city FROM Addresses AS T1 JOIN Students AS T2 ON T1.address_id = T2.address_id\n",
      "C√¢u tham chi·∫øu: SELECT DISTINCT T1.city FROM addresses AS T1 JOIN people_addresses AS T2 ON T1.address_id = T2.address_id JOIN students AS T3 ON T2.person_id = T3.student_id\n",
      "\n",
      "s·ªë c·∫∑p kh√¥ng kh·ªõp:  25\n"
     ]
    }
   ],
   "source": [
    "# ƒê·∫ßu ti√™n, t√≠nh to√°n k·∫øt qu·∫£ exact_match\n",
    "results_exact_match = exact_match_metric.compute(predictions=predictions, references=target)\n",
    "print(results_exact_match)\n",
    "# L·∫∑p qua c√°c c·∫∑p c√¢u d·ª± ƒëo√°n v√† c√¢u tham chi·∫øu ƒë·ªÉ in ra c√°c c·∫∑p kh√¥ng kh·ªõp\n",
    "error =0\n",
    "for idx, (predicted_sql, reference_sql) in enumerate(zip(predictions, target)):\n",
    "    if predicted_sql != reference_sql:\n",
    "        error += 1\n",
    "        print(f\"C·∫∑p kh√¥ng kh·ªõp th·ª© {idx + 1}:\")\n",
    "        print(\"C√¢u d·ª± ƒëo√°n:\", predicted_sql)\n",
    "        print(\"C√¢u tham chi·∫øu:\", reference_sql)\n",
    "        print()  # In m·ªôt d√≤ng tr·ªëng ƒë·ªÉ ph√¢n bi·ªát c√°c c·∫∑p kh√¥ng kh·ªõp\n",
    "print(\"s·ªë c·∫∑p kh√¥ng kh·ªõp: \", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "refs = [\"SELECT max(budget_in_billions), min(budget_in_billions) FROM department\"\n",
    "        , \"SELECT avg(num_employees) FROM department WHERE rank BETWEEN 10 AND 15\"\n",
    "        , \"SELECT DISTINCT T1.age FROM management AS T2 JOIN head AS T1 ON T1.head_id = T2.head_id WHERE T2.temporary_acting = 'Yes'\"\n",
    "        , \"SELECT Hosts FROM farm_competition WHERE Theme!= 'Aliens'\"]\n",
    "preds = [\"SELECT max(budget_in_billion), min(budget_in_billion) FROM department\"\n",
    "         , \"SELECT avg(num_employees) FROM department WHERE rank BETWEEN 10 AND 15\"\n",
    "         , \"SELECT DISTINCT T1.age FROM management AS T1 JOIN head AS T2 ON T1.head_id = T2.head_id WHERE T2.temporary_acting = 'Yes'\"\n",
    "         , \"SELECT Hosts FROM farm_competition WHERE Theme!= 'Aliens'\"]\n",
    "results = exact_match_metric.compute(references=refs, predictions=preds, regexes_to_ignore=[\" \", \"s\",\"es\",\"!\", \"ing\"], ignore_case=True, ignore_punctuation=False, ignore_numbers=True)\n",
    "print(round(results[\"exact_match\"], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.0\n"
     ]
    }
   ],
   "source": [
    "results = exact_match_metric.compute(references=target, predictions=predictions, regexes_to_ignore=[\" \", \"s\",\"es\",\"!\", \"ing\"], ignore_case=True, ignore_punctuation=True, ignore_numbers=True)\n",
    "print(round(results[\"exact_match\"], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric: bert_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Precision: ƒê√¢y l√† t·ª∑ l·ªá gi·ªØa s·ªë l∆∞·ª£ng c√°c d·ª± ƒëo√°n ƒë√∫ng v√† t·ªïng s·ªë l∆∞·ª£ng c√°c d·ª± ƒëo√°n ƒë∆∞·ª£c th·ª±c hi·ªán. Trong ng·ªØ c·∫£nh c·ªßa BERTScore, precision ƒëo l∆∞·ªùng t·ª∑ l·ªá token trong d·ª± ƒëo√°n m√† m√¥ h√¨nh ƒë√∫ng ƒë·∫Øn so v·ªõi t·∫•t c·∫£ c√°c token trong d·ª± ƒëo√°n.\n",
    "\n",
    "Recall: ƒê√¢y l√† t·ª∑ l·ªá gi·ªØa s·ªë l∆∞·ª£ng c√°c d·ª± ƒëo√°n ƒë√∫ng v√† t·ªïng s·ªë l∆∞·ª£ng c√°c token trong tham chi·∫øu. Recall ƒëo l∆∞·ªùng t·ª∑ l·ªá token trong tham chi·∫øu m√† m√¥ h√¨nh ƒë√∫ng ƒë·∫Øn so v·ªõi t·∫•t c·∫£ c√°c token trong tham chi·∫øu.\n",
    "\n",
    "F1-score: ƒê√¢y l√† trung b√¨nh ƒëi·ªÅu h√≤a c·ªßa precision v√† recall. F1-score cung c·∫•p m·ªôt c√°ch t·ªïng h·ª£p ƒë·ªÉ ƒëo l∆∞·ªùng hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh, b·∫±ng c√°ch c√¢n nh·∫Øc c·∫£ precision v√† recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_results(results):\n",
    "    average_results = {}\n",
    "    for key in results:\n",
    "        if isinstance(results[key], list) and all(isinstance(x, (int, float)) for x in results[key]):\n",
    "            average_results[key] = np.mean(results[key])\n",
    "        else:\n",
    "            average_results[key] = None\n",
    "    return average_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': [0.9867746829986572, 1.0000001192092896, 0.9980701804161072, 1.0], 'recall': [0.9867746829986572, 1.0000001192092896, 0.9980701804161072, 1.0], 'f1': [0.9867746829986572, 1.0000001192092896, 0.9980701804161072, 1.0], 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=4.41.1)'}\n"
     ]
    }
   ],
   "source": [
    "pred = [\"SELECT max(budget_in_billion), min(budget_in_billion) FROM department\"\n",
    "         , \"SELECT avg(num_employees) FROM department WHERE rank BETWEEN 10 AND 15\"\n",
    "         , \"SELECT DISTINCT T1.age FROM management AS T1 JOIN head AS T2 ON T1.head_id = T2.head_id WHERE T2.temporary_acting = 'Yes'\"\n",
    "         , \"SELECT Hosts FROM farm_competition WHERE Theme!= 'Aliens'\"]\n",
    "ref = [\"SELECT max(budget_in_billions), min(budget_in_billions) FROM department\"\n",
    "        , \"SELECT avg(num_employees) FROM department WHERE rank BETWEEN 10 AND 15\"\n",
    "        , \"SELECT DISTINCT T1.age FROM management AS T2 JOIN head AS T1 ON T1.head_id = T2.head_id WHERE T2.temporary_acting = 'Yes'\"\n",
    "        , \"SELECT Hosts FROM farm_competition WHERE Theme!= 'Aliens'\"]\n",
    "results = bertscore.compute(predictions=pred, references=ref, model_type=\"distilbert-base-uncased\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20520\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K·∫øt qu·∫£ trung b√¨nh ch√≠nh x√°c: {'precision': 0.9929775285720825, 'recall': 0.9873931401968002, 'f1': 0.9900400310754776, 'hashcode': None}\n"
     ]
    }
   ],
   "source": [
    "results_bertscore = bertscore.compute(predictions=predictions, references=target, model_type=\"bert-base-uncased\")\n",
    "print(\"K·∫øt qu·∫£ trung b√¨nh ch√≠nh x√°c:\", compute_average_results(results_bertscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with new question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the first and last names of all customers with more than 2 payments?\n",
      "Generated SQL query: SELECT T2.first_name, T2.last_name FROM Customer_Payments AS T1 JOIN Customers AS T2 ON T1.customer_id = T2.customer_id GROUP BY T1.customer_id HAVING count(*) > 2\n"
     ]
    }
   ],
   "source": [
    "# Th·ª≠ nghi·ªám v·ªõi c√¢u h·ªèi m·ªõi\n",
    "new_question = \"What are the first and last names of all customers with more than 2 payments?\"\n",
    "input_ids = tokenizer.encode(new_question, return_tensors='pt')\n",
    "outputs = model.generate(input_ids=input_ids, max_length=100, num_beams=5, early_stopping=True)\n",
    "sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Question: {new_question}\")\n",
    "print(f\"Generated SQL query: {sql_query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What team has more than 49 laps and a grid of 8?\n",
      "Generated SQL query: SELECT Team FROM laps WHERE laps > 49 INTERSECT SELECT Team FROM grid WHERE grid = 8\n"
     ]
    }
   ],
   "source": [
    "# Th·ª≠ nghi·ªám v·ªõi c√¢u h·ªèi m·ªõi\n",
    "new_question = \"What team has more than 49 laps and a grid of 8?\"\n",
    "input_ids = tokenizer.encode(new_question, return_tensors='pt')\n",
    "outputs = model.generate(input_ids=input_ids, max_length=100, num_beams=5, early_stopping=True)\n",
    "sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Question: {new_question}\")\n",
    "print(f\"Generated SQL query: {sql_query}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1456187,
     "sourceId": 2409983,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30407,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
